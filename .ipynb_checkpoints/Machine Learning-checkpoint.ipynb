{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install pymongo\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pymongo.mongo_client.MongoClient"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pymongo.MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient('35.164.217.46', 27016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = client.wiki_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search(phrase):\n",
    "    phrase = re.sub('\\s', '+', phrase)\n",
    "    query = 'http://en.wikipedia.org/w/api.php?action=query&format=json&list=categorymembers&cmtitle=Category%3A+{}&cmlimit=max'.format(phrase)\n",
    "    QR = requests.get(query)\n",
    "    return(pd.DataFrame(QR.json()['query']['categorymembers']))\n",
    "#the categorymemeber is nested in the query, nested dictionaries \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Example code to use to test with different url parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://en.wikipedia.org/w/api.php?action=query&format=json&   '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_query = 'http://en.wikipedia.org/w/api.php?action=query&format=json&   '.format()\n",
    "search_page = requests.get(page_query)\n",
    "search_page.json()\n",
    "page_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batchcomplete': '',\n",
       " 'continue': {'cmcontinue': 'page|37414d2f3d04492f273d4b2f414b2f0113018f818f838f08|46222904',\n",
       "  'continue': '-||'},\n",
       " 'query': {'categorymembers': [{'ns': 0,\n",
       "    'pageid': 15795950,\n",
       "    'title': 'Activity recognition'},\n",
       "   {'ns': 0, 'pageid': 41916168, 'title': 'AlchemyAPI'},\n",
       "   {'ns': 0, 'pageid': 55075082, 'title': 'BigDL'},\n",
       "   {'ns': 0, 'pageid': 53631046, 'title': 'Caffe (software)'},\n",
       "   {'ns': 0,\n",
       "    'pageid': 49119569,\n",
       "    'title': 'Comparison of deep learning software'},\n",
       "   {'ns': 0, 'pageid': 41916447, 'title': 'Cortica'},\n",
       "   {'ns': 0, 'pageid': 34529351, 'title': 'DARPA LAGR Program'},\n",
       "   {'ns': 0, 'pageid': 43169442, 'title': 'Deeplearning4j'},\n",
       "   {'ns': 0, 'pageid': 38818825, 'title': 'Diffbot'},\n",
       "   {'ns': 0, 'pageid': 41184517, 'title': 'Google Brain'}]}}"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This gives me all the page ids for the subcategories\n",
    "#need to find a way to get the list of PageIds to get all those pages info, see if I can createa list \n",
    "#response 200 means that the connection worked, you want to get a 200\n",
    "page_query = 'http://en.wikipedia.org/w/api.php?action=query&format=json&&list=categorymembers&cmtitle=Category:Applied_machine_learning'.format()\n",
    "search_page = requests.get(page_query)\n",
    "pages_ids = search_page.json()\n",
    "pages_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nest_dict = pages_ids['query']['categorymembers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_query = 'http://en.wikipedia.org/w/api.php?action=query&format=json&&list=categorymembers&cmtitle=Category:Machine_learning&cmlimit=max&cmtype=subcat'.format()\n",
    "search_page = requests.get(page_query)\n",
    "pages_ids = search_page.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wiki Machine Learning ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_query = 'http://en.wikipedia.org/w/api.php?action=query&format=json&list=categorymembers&cmtitle=Category:Machine_learning&cmlimit=max'.format()\n",
    "search_page = requests.get(page_query)\n",
    "pages_ids = search_page.json()\n",
    "pages_ids\n",
    "machine_learningdf = pd.DataFrame(pages_ids['query']['categorymembers'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ns</th>\n",
       "      <th>pageid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>43385931</td>\n",
       "      <td>Data exploration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>49082762</td>\n",
       "      <td>List of datasets for machine learning research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>233488</td>\n",
       "      <td>Machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>53587467</td>\n",
       "      <td>Outline of machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3771060</td>\n",
       "      <td>Accuracy paradox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>43808044</td>\n",
       "      <td>Action model learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>28801798</td>\n",
       "      <td>Active learning (machine learning)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>45049676</td>\n",
       "      <td>Adversarial machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>52642349</td>\n",
       "      <td>AIVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>30511763</td>\n",
       "      <td>AIXI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>50773876</td>\n",
       "      <td>Algorithm selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>55817338</td>\n",
       "      <td>Algorithmic bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>20890511</td>\n",
       "      <td>Algorithmic inference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>49242352</td>\n",
       "      <td>AlphaGo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>55572262</td>\n",
       "      <td>AlphaGo Zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>19463198</td>\n",
       "      <td>Apprenticeship learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>55843837</td>\n",
       "      <td>Automated machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>14003441</td>\n",
       "      <td>Bag-of-words model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>31877832</td>\n",
       "      <td>Ball tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>9732182</td>\n",
       "      <td>Base rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>35867897</td>\n",
       "      <td>Bayesian interpretation of kernel regularization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>40973765</td>\n",
       "      <td>Bayesian optimization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>50211107</td>\n",
       "      <td>Bayesian structural time series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>40678189</td>\n",
       "      <td>Bias–variance tradeoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>55075082</td>\n",
       "      <td>BigDL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>205393</td>\n",
       "      <td>Binary classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>50646178</td>\n",
       "      <td>Bing Predicts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1191936</td>\n",
       "      <td>Bongard problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>44439173</td>\n",
       "      <td>Bradley–Terry model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>53631046</td>\n",
       "      <td>Caffe (software)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0</td>\n",
       "      <td>29288159</td>\n",
       "      <td>Sequence labeling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0</td>\n",
       "      <td>38059657</td>\n",
       "      <td>Similarity learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0</td>\n",
       "      <td>405562</td>\n",
       "      <td>Solomonoff's theory of inductive inference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0</td>\n",
       "      <td>48813654</td>\n",
       "      <td>Sparse dictionary learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0</td>\n",
       "      <td>50227596</td>\n",
       "      <td>Spike-and-slab variable selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0</td>\n",
       "      <td>33886025</td>\n",
       "      <td>Stability (learning theory)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0</td>\n",
       "      <td>1579244</td>\n",
       "      <td>Statistical classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0</td>\n",
       "      <td>1053303</td>\n",
       "      <td>Statistical learning theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0</td>\n",
       "      <td>19667111</td>\n",
       "      <td>Statistical relational learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0</td>\n",
       "      <td>47845063</td>\n",
       "      <td>Stochastic block model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0</td>\n",
       "      <td>10704974</td>\n",
       "      <td>Structural risk minimization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0</td>\n",
       "      <td>48844125</td>\n",
       "      <td>Structured sparsity regularization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0</td>\n",
       "      <td>3119546</td>\n",
       "      <td>Subclass reachability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0</td>\n",
       "      <td>20926</td>\n",
       "      <td>Supervised learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0</td>\n",
       "      <td>50828755</td>\n",
       "      <td>Timeline of machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0</td>\n",
       "      <td>1514392</td>\n",
       "      <td>Training, test, and validation sets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0</td>\n",
       "      <td>960361</td>\n",
       "      <td>Transduction (machine learning)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0</td>\n",
       "      <td>3920550</td>\n",
       "      <td>Transfer learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0</td>\n",
       "      <td>47577902</td>\n",
       "      <td>Trax Image Recognition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0</td>\n",
       "      <td>5077439</td>\n",
       "      <td>Ugly duckling theorem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0</td>\n",
       "      <td>19058043</td>\n",
       "      <td>Uncertain data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0</td>\n",
       "      <td>22999791</td>\n",
       "      <td>Uniform convergence in probability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0</td>\n",
       "      <td>37787103</td>\n",
       "      <td>Universal portfolio algorithm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0</td>\n",
       "      <td>233497</td>\n",
       "      <td>Unsupervised learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0</td>\n",
       "      <td>47228422</td>\n",
       "      <td>User behavior analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0</td>\n",
       "      <td>39945557</td>\n",
       "      <td>Validation set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0</td>\n",
       "      <td>43502368</td>\n",
       "      <td>Vanishing gradient problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0</td>\n",
       "      <td>7578809</td>\n",
       "      <td>Version space learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0</td>\n",
       "      <td>52992310</td>\n",
       "      <td>VGG Image Annotator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0</td>\n",
       "      <td>47527969</td>\n",
       "      <td>Word2vec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ns    pageid                                             title\n",
       "0     0  43385931                                  Data exploration\n",
       "1     0  49082762    List of datasets for machine learning research\n",
       "2     0    233488                                  Machine learning\n",
       "3     0  53587467                       Outline of machine learning\n",
       "4     0   3771060                                  Accuracy paradox\n",
       "5     0  43808044                             Action model learning\n",
       "6     0  28801798                Active learning (machine learning)\n",
       "7     0  45049676                      Adversarial machine learning\n",
       "8     0  52642349                                              AIVA\n",
       "9     0  30511763                                              AIXI\n",
       "10    0  50773876                               Algorithm selection\n",
       "11    0  55817338                                  Algorithmic bias\n",
       "12    0  20890511                             Algorithmic inference\n",
       "13    0  49242352                                           AlphaGo\n",
       "14    0  55572262                                      AlphaGo Zero\n",
       "15    0  19463198                           Apprenticeship learning\n",
       "16    0  55843837                        Automated machine learning\n",
       "18    0  14003441                                Bag-of-words model\n",
       "19    0  31877832                                         Ball tree\n",
       "20    0   9732182                                         Base rate\n",
       "21    0  35867897  Bayesian interpretation of kernel regularization\n",
       "22    0  40973765                             Bayesian optimization\n",
       "23    0  50211107                   Bayesian structural time series\n",
       "24    0  40678189                            Bias–variance tradeoff\n",
       "25    0  55075082                                             BigDL\n",
       "26    0    205393                             Binary classification\n",
       "27    0  50646178                                     Bing Predicts\n",
       "28    0   1191936                                   Bongard problem\n",
       "29    0  44439173                               Bradley–Terry model\n",
       "30    0  53631046                                  Caffe (software)\n",
       "..   ..       ...                                               ...\n",
       "171   0  29288159                                 Sequence labeling\n",
       "172   0  38059657                               Similarity learning\n",
       "173   0    405562        Solomonoff's theory of inductive inference\n",
       "174   0  48813654                        Sparse dictionary learning\n",
       "175   0  50227596                 Spike-and-slab variable selection\n",
       "176   0  33886025                       Stability (learning theory)\n",
       "177   0   1579244                        Statistical classification\n",
       "178   0   1053303                       Statistical learning theory\n",
       "179   0  19667111                   Statistical relational learning\n",
       "180   0  47845063                            Stochastic block model\n",
       "181   0  10704974                      Structural risk minimization\n",
       "182   0  48844125                Structured sparsity regularization\n",
       "183   0   3119546                             Subclass reachability\n",
       "184   0     20926                               Supervised learning\n",
       "185   0  50828755                      Timeline of machine learning\n",
       "186   0   1514392               Training, test, and validation sets\n",
       "187   0    960361                   Transduction (machine learning)\n",
       "188   0   3920550                                 Transfer learning\n",
       "189   0  47577902                            Trax Image Recognition\n",
       "190   0   5077439                             Ugly duckling theorem\n",
       "191   0  19058043                                    Uncertain data\n",
       "192   0  22999791                Uniform convergence in probability\n",
       "193   0  37787103                     Universal portfolio algorithm\n",
       "194   0    233497                             Unsupervised learning\n",
       "195   0  47228422                           User behavior analytics\n",
       "196   0  39945557                                    Validation set\n",
       "197   0  43502368                        Vanishing gradient problem\n",
       "198   0   7578809                            Version space learning\n",
       "199   0  52992310                               VGG Image Annotator\n",
       "200   0  47527969                                          Word2vec\n",
       "\n",
       "[199 rows x 3 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "just_the_pages = machine_learningdf[machine_learningdf['ns'] == 0]\n",
    "#just_the_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_categories = machine_learningdf[machine_learningdf['ns'] == 14]\n",
    "sub_cat_list = list(sub_categories['pageid'])\n",
    "len(sub_cat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_title_sub = sub_categories['title']\n",
    "#len(just_title_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_pagesdf = machine_learningdf[machine_learningdf['ns'] == 0]\n",
    "machine_pageslist = list(machine_pagesdf['pageid'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#machine_pagesdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just the 199 pages of Machine Learning with just text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pages = []\n",
    "\n",
    "def striphtml(data):\n",
    "    p = re.compile(r'<.*?>')\n",
    "    return p.sub('', data)\n",
    "\n",
    "for page in machine_pageslist:\n",
    "#def get_page_contents(page):\n",
    "    #for page in category_list:\n",
    "        query = 'http://en.wikipedia.org/w/api.php?action=query&prop=extracts&\\\n",
    "             rvprop=content&rvsection=0&format=json&pageids={}'.format(str(page))\n",
    "    \n",
    "        my_request2 = requests.get(query).json()\n",
    "\n",
    "    \n",
    "        all_pages.append(striphtml(my_request2['query']['pages'][str(page)]['extract']).replace(\"'\",''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_listdf = pd.DataFrame(all_pages, columns=['text'])\n",
    "#machine_listdf = pd.concat([machine_listdf, just_the_pages['title']], axis=1)\n",
    "machinelearning_title = machine_pagesdf['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Sub Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_contents(pageid):\n",
    "    #for page in pageid:\n",
    "        query15 = 'http://en.wikipedia.org/w/api.php?action=query&format=json&cmpageid={}&cmtype=subcat'.format(page)\n",
    "        my_request15 = requests.get(query15)\n",
    "        request20 = my_request15.json()\n",
    "        \n",
    "        return request20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_list(ids):\n",
    "    list_cleaner = []\n",
    "    for a in range(len(ids)):\n",
    "        for b in ids[a]:\n",
    "            list_cleaner.append(b)\n",
    "    lists_cleaned = pd.DataFrame(list_cleaner)\n",
    "    return lists_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub Sub Category PageIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_second_level = []\n",
    "for page in sub_cat_list:\n",
    "    page_query2 = 'http://en.wikipedia.org/w/api.php?action=query&format=json&list=categorymembers&cmpageid={}&cmnamespace=14&cmlimit=max&cmtype=subcat'.format(page)\n",
    "    sub_second_level.append(requests.get(page_query2).json()['query']['categorymembers'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_second_leveldf = clean_list(sub_second_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ns</th>\n",
       "      <th>pageid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>49119651</td>\n",
       "      <td>Category:Deep learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>3735046</td>\n",
       "      <td>Category:Neural network software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>42936114</td>\n",
       "      <td>Category:Artificial neural networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>17594154</td>\n",
       "      <td>Category:Decision trees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>3985352</td>\n",
       "      <td>Category:Ensemble learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>15325165</td>\n",
       "      <td>Category:Cluster analysis algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>30033882</td>\n",
       "      <td>Category:Clustering criteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>38708030</td>\n",
       "      <td>Category:Social network analysis software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>16215923</td>\n",
       "      <td>Category:Datasets in computer vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>36425555</td>\n",
       "      <td>Category:Factor analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14</td>\n",
       "      <td>37176176</td>\n",
       "      <td>Category:Gene expression programming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>868737</td>\n",
       "      <td>Category:Genetic algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>3061615</td>\n",
       "      <td>Category:Genetic programming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>51088850</td>\n",
       "      <td>Category:Nature-inspired metaheuristics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>31176997</td>\n",
       "      <td>Category:Support vector machines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>36425555</td>\n",
       "      <td>Category:Factor analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14</td>\n",
       "      <td>29967998</td>\n",
       "      <td>Category:Structural equation models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14</td>\n",
       "      <td>868737</td>\n",
       "      <td>Category:Genetic algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14</td>\n",
       "      <td>31813917</td>\n",
       "      <td>Category:Hidden Markov models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14</td>\n",
       "      <td>22718453</td>\n",
       "      <td>Category:Markov networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14</td>\n",
       "      <td>42452485</td>\n",
       "      <td>Category:Language modeling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14</td>\n",
       "      <td>22691076</td>\n",
       "      <td>Category:Graphical models</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ns    pageid                                      title\n",
       "0   14  49119651                     Category:Deep learning\n",
       "1   14   3735046           Category:Neural network software\n",
       "2   14  42936114        Category:Artificial neural networks\n",
       "3   14  17594154                    Category:Decision trees\n",
       "4   14   3985352                 Category:Ensemble learning\n",
       "5   14  15325165       Category:Cluster analysis algorithms\n",
       "6   14  30033882               Category:Clustering criteria\n",
       "7   14  38708030  Category:Social network analysis software\n",
       "8   14  16215923       Category:Datasets in computer vision\n",
       "9   14  36425555                   Category:Factor analysis\n",
       "10  14  37176176       Category:Gene expression programming\n",
       "11  14    868737                Category:Genetic algorithms\n",
       "12  14   3061615               Category:Genetic programming\n",
       "13  14  51088850    Category:Nature-inspired metaheuristics\n",
       "14  14  31176997           Category:Support vector machines\n",
       "15  14  36425555                   Category:Factor analysis\n",
       "16  14  29967998        Category:Structural equation models\n",
       "17  14    868737                Category:Genetic algorithms\n",
       "18  14  31813917              Category:Hidden Markov models\n",
       "19  14  22718453                   Category:Markov networks\n",
       "20  14  42452485                 Category:Language modeling\n",
       "21  14  22691076                  Category:Graphical models"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_second_leveldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49119651,\n",
       " 3735046,\n",
       " 42936114,\n",
       " 17594154,\n",
       " 3985352,\n",
       " 15325165,\n",
       " 30033882,\n",
       " 38708030,\n",
       " 16215923,\n",
       " 36425555,\n",
       " 37176176,\n",
       " 868737,\n",
       " 3061615,\n",
       " 51088850,\n",
       " 31176997,\n",
       " 36425555,\n",
       " 29967998,\n",
       " 868737,\n",
       " 31813917,\n",
       " 22718453,\n",
       " 42452485,\n",
       " 22691076]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_second_list = list(sub_second_leveldf['pageid'])\n",
    "sub_second_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to go into the index and grab the x in range that has value, ie the informatino of pageid\n",
    "#for x in range(sub_pages_list):\n",
    "#gets rid of empty list\n",
    "#run twice to get rid of all the empyt lists\n",
    "for x in range(len(sub_pages_list)):\n",
    "    if sub_pages_list[x] == []:\n",
    "        del sub_pages_list[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All the PageIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cat_ids = sub_second_list + sub_cat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_cat_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages_articles(lists3):\n",
    "    all_pages_needed = []\n",
    "    for number in lists3:\n",
    "        pagequery = 'http://en.wikipedia.org/w/api.php?action=query&format=json&&list=categorymembers&cmpageid={}&cmlimit=max'.format(number)\n",
    "        search_page55 = requests.get(pagequery)\n",
    "        pages = search_page55.json()['query']['categorymembers']\n",
    "        all_pages_needed.append(pages)\n",
    "    return all_pages_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pages = clean_list(get_pages_articles(all_cat_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ns</th>\n",
       "      <th>pageid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32472154</td>\n",
       "      <td>Deep learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>52642349</td>\n",
       "      <td>AIVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>52801963</td>\n",
       "      <td>AlexNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>51545339</td>\n",
       "      <td>Apache SINGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>55075082</td>\n",
       "      <td>BigDL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>53631046</td>\n",
       "      <td>Caffe (software)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>49119569</td>\n",
       "      <td>Comparison of deep learning software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>43169442</td>\n",
       "      <td>Deeplearning4j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>41755648</td>\n",
       "      <td>DeepMind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>11273721</td>\n",
       "      <td>Hierarchical temporal memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>51650259</td>\n",
       "      <td>Keras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>49830146</td>\n",
       "      <td>Microsoft Cognitive Toolkit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>55690224</td>\n",
       "      <td>Msg.ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>52513310</td>\n",
       "      <td>MXNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>49594059</td>\n",
       "      <td>ND4J (software)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>47012074</td>\n",
       "      <td>Neural Designer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1643246</td>\n",
       "      <td>Numenta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>42129549</td>\n",
       "      <td>OpenNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>41732818</td>\n",
       "      <td>Qloo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>48508507</td>\n",
       "      <td>TensorFlow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>33520809</td>\n",
       "      <td>Theano (software)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>42571226</td>\n",
       "      <td>Torch (machine learning)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>54186633</td>\n",
       "      <td>Aika (software)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>52801963</td>\n",
       "      <td>AlexNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>50551441</td>\n",
       "      <td>DeepArt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>47332350</td>\n",
       "      <td>DeepDream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>43169442</td>\n",
       "      <td>Deeplearning4j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>15605446</td>\n",
       "      <td>EDLUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>3562081</td>\n",
       "      <td>Emergent (software)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>26471190</td>\n",
       "      <td>Encog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>0</td>\n",
       "      <td>28934119</td>\n",
       "      <td>Topic model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>0</td>\n",
       "      <td>2061486</td>\n",
       "      <td>Trigram tagger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>0</td>\n",
       "      <td>3656587</td>\n",
       "      <td>Variable rules analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>0</td>\n",
       "      <td>13125238</td>\n",
       "      <td>Writer invariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>14</td>\n",
       "      <td>42452485</td>\n",
       "      <td>Category:Language modeling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>0</td>\n",
       "      <td>28255458</td>\n",
       "      <td>Constrained conditional model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>0</td>\n",
       "      <td>53985910</td>\n",
       "      <td>Structured kNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>0</td>\n",
       "      <td>27260435</td>\n",
       "      <td>Structured prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>0</td>\n",
       "      <td>20027065</td>\n",
       "      <td>Structured support vector machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>14</td>\n",
       "      <td>22691076</td>\n",
       "      <td>Category:Graphical models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>0</td>\n",
       "      <td>33742232</td>\n",
       "      <td>Restricted Boltzmann machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>0</td>\n",
       "      <td>65309</td>\n",
       "      <td>Support vector machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>0</td>\n",
       "      <td>33100241</td>\n",
       "      <td>Hinge loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>0</td>\n",
       "      <td>26849824</td>\n",
       "      <td>Least squares support vector machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>0</td>\n",
       "      <td>17707632</td>\n",
       "      <td>Margin (machine learning)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>0</td>\n",
       "      <td>34060917</td>\n",
       "      <td>Ranking SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>0</td>\n",
       "      <td>35857112</td>\n",
       "      <td>Regularization perspectives on support vector ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>0</td>\n",
       "      <td>20154492</td>\n",
       "      <td>Sequential minimal optimization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>0</td>\n",
       "      <td>20027065</td>\n",
       "      <td>Structured support vector machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>0</td>\n",
       "      <td>233497</td>\n",
       "      <td>Unsupervised learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>0</td>\n",
       "      <td>6836612</td>\n",
       "      <td>Autoencoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>0</td>\n",
       "      <td>39177819</td>\n",
       "      <td>Cognitive computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>0</td>\n",
       "      <td>26266110</td>\n",
       "      <td>Competitive learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>0</td>\n",
       "      <td>50073184</td>\n",
       "      <td>Generative adversarial network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>0</td>\n",
       "      <td>404084</td>\n",
       "      <td>Hebbian theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>0</td>\n",
       "      <td>11273721</td>\n",
       "      <td>Hierarchical temporal memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>0</td>\n",
       "      <td>33742232</td>\n",
       "      <td>Restricted Boltzmann machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>0</td>\n",
       "      <td>76996</td>\n",
       "      <td>Self-organizing map</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>0</td>\n",
       "      <td>48813654</td>\n",
       "      <td>Sparse dictionary learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>0</td>\n",
       "      <td>47805</td>\n",
       "      <td>Vector quantization</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1364 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ns    pageid                                              title\n",
       "0      0  32472154                                      Deep learning\n",
       "1      0  52642349                                               AIVA\n",
       "2      0  52801963                                            AlexNet\n",
       "3      0  51545339                                       Apache SINGA\n",
       "4      0  55075082                                              BigDL\n",
       "5      0  53631046                                   Caffe (software)\n",
       "6      0  49119569               Comparison of deep learning software\n",
       "7      0  43169442                                     Deeplearning4j\n",
       "8      0  41755648                                           DeepMind\n",
       "9      0  11273721                       Hierarchical temporal memory\n",
       "10     0  51650259                                              Keras\n",
       "11     0  49830146                        Microsoft Cognitive Toolkit\n",
       "12     0  55690224                                             Msg.ai\n",
       "13     0  52513310                                              MXNet\n",
       "14     0  49594059                                    ND4J (software)\n",
       "15     0  47012074                                    Neural Designer\n",
       "16     0   1643246                                            Numenta\n",
       "17     0  42129549                                             OpenNN\n",
       "18     0  41732818                                               Qloo\n",
       "19     0  48508507                                         TensorFlow\n",
       "20     0  33520809                                  Theano (software)\n",
       "21     0  42571226                           Torch (machine learning)\n",
       "22     0  54186633                                    Aika (software)\n",
       "23     0  52801963                                            AlexNet\n",
       "24     0  50551441                                            DeepArt\n",
       "25     0  47332350                                          DeepDream\n",
       "26     0  43169442                                     Deeplearning4j\n",
       "27     0  15605446                                              EDLUT\n",
       "28     0   3562081                                Emergent (software)\n",
       "29     0  26471190                                              Encog\n",
       "...   ..       ...                                                ...\n",
       "1334   0  28934119                                        Topic model\n",
       "1335   0   2061486                                     Trigram tagger\n",
       "1336   0   3656587                            Variable rules analysis\n",
       "1337   0  13125238                                   Writer invariant\n",
       "1338  14  42452485                         Category:Language modeling\n",
       "1339   0  28255458                      Constrained conditional model\n",
       "1340   0  53985910                                     Structured kNN\n",
       "1341   0  27260435                              Structured prediction\n",
       "1342   0  20027065                  Structured support vector machine\n",
       "1343  14  22691076                          Category:Graphical models\n",
       "1344   0  33742232                       Restricted Boltzmann machine\n",
       "1345   0     65309                             Support vector machine\n",
       "1346   0  33100241                                         Hinge loss\n",
       "1347   0  26849824               Least squares support vector machine\n",
       "1348   0  17707632                          Margin (machine learning)\n",
       "1349   0  34060917                                        Ranking SVM\n",
       "1350   0  35857112  Regularization perspectives on support vector ...\n",
       "1351   0  20154492                    Sequential minimal optimization\n",
       "1352   0  20027065                  Structured support vector machine\n",
       "1353   0    233497                              Unsupervised learning\n",
       "1354   0   6836612                                        Autoencoder\n",
       "1355   0  39177819                                 Cognitive computer\n",
       "1356   0  26266110                               Competitive learning\n",
       "1357   0  50073184                     Generative adversarial network\n",
       "1358   0    404084                                     Hebbian theory\n",
       "1359   0  11273721                       Hierarchical temporal memory\n",
       "1360   0  33742232                       Restricted Boltzmann machine\n",
       "1361   0     76996                                Self-organizing map\n",
       "1362   0  48813654                         Sparse dictionary learning\n",
       "1363   0     47805                                Vector quantization\n",
       "\n",
       "[1364 rows x 3 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pages.drop_duplicates(['ns', 'title', 'pageid'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alltitles = pd.concat([all_pages, machinelearning_title], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles_df.drop_duplicates(inplace=True, keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles_df = pd.DataFrame(all_titles_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_titles_list = all_titles_df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "everything = pd.concat([all_articles_pageids, just_the_pages, all_pages], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "957"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pages_list = list(all_pages['pageid'])\n",
    "len(all_pages_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "everything.drop_duplicates(['ns', 'pageid', 'title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1114"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "everything_pages = list(everything['pageid'])\n",
    "len(everything_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_titles = pd.DataFrame(everything['title'])\n",
    "only_titles.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Activity recognition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AlchemyAPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BigDL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Caffe (software)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Comparison of deep learning software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cortica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DARPA LAGR Program</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Deeplearning4j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Diffbot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Google Brain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Intel RealSense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IRCF360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jabberwacky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Keras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kinect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Language Acquisition Device (computer)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MysteryVibe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ND4J (software)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Nest Labs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Niki.ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Numenta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Onnx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>OpenNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Portable Format for Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Predictive Model Markup Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Quantum Artificial Intelligence Lab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Quick, Draw!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Reasoning system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sense Networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>Semantic analysis (machine learning)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>Semantic folding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>Semi-supervised learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>Sequence labeling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>Similarity learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>Solomonoff's theory of inductive inference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>Spike-and-slab variable selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>Stability (learning theory)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>Statistical learning theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>Statistical relational learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>Stochastic block model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>Structural risk minimization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>Structured sparsity regularization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>Subclass reachability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>Supervised learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>Timeline of machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>Transduction (machine learning)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>Transfer learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>Trax Image Recognition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>Ugly duckling theorem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>Uncertain data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>Uniform convergence in probability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>Universal portfolio algorithm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>User behavior analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>Validation set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>Version space learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>File:Decision tree for IUPAC polymer nomenclat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>Category:Artificial immune systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>Category:Bayesian networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>Category:Causal inference</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1114 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title\n",
       "0                                  Activity recognition\n",
       "1                                            AlchemyAPI\n",
       "2                                                 BigDL\n",
       "3                                      Caffe (software)\n",
       "4                  Comparison of deep learning software\n",
       "5                                               Cortica\n",
       "6                                    DARPA LAGR Program\n",
       "7                                        Deeplearning4j\n",
       "8                                               Diffbot\n",
       "9                                          Google Brain\n",
       "10                                      Intel RealSense\n",
       "11                                              IRCF360\n",
       "12                                          Jabberwacky\n",
       "13                                               Kaggle\n",
       "14                                                Keras\n",
       "15                                               Kinect\n",
       "16               Language Acquisition Device (computer)\n",
       "17                                          MysteryVibe\n",
       "18                                      ND4J (software)\n",
       "19                                            Nest Labs\n",
       "20                                              Niki.ai\n",
       "21                                              Numenta\n",
       "22                                                 Onnx\n",
       "23                                               OpenNN\n",
       "24                        Portable Format for Analytics\n",
       "25                     Predictive Model Markup Language\n",
       "26                  Quantum Artificial Intelligence Lab\n",
       "27                                         Quick, Draw!\n",
       "28                                     Reasoning system\n",
       "29                                       Sense Networks\n",
       "...                                                 ...\n",
       "1119               Semantic analysis (machine learning)\n",
       "1120                                   Semantic folding\n",
       "1121                           Semi-supervised learning\n",
       "1122                                  Sequence labeling\n",
       "1123                                Similarity learning\n",
       "1124         Solomonoff's theory of inductive inference\n",
       "1126                  Spike-and-slab variable selection\n",
       "1127                        Stability (learning theory)\n",
       "1129                        Statistical learning theory\n",
       "1130                    Statistical relational learning\n",
       "1131                             Stochastic block model\n",
       "1132                       Structural risk minimization\n",
       "1133                 Structured sparsity regularization\n",
       "1134                              Subclass reachability\n",
       "1135                                Supervised learning\n",
       "1136                       Timeline of machine learning\n",
       "1138                    Transduction (machine learning)\n",
       "1139                                  Transfer learning\n",
       "1140                             Trax Image Recognition\n",
       "1141                              Ugly duckling theorem\n",
       "1142                                     Uncertain data\n",
       "1143                 Uniform convergence in probability\n",
       "1144                      Universal portfolio algorithm\n",
       "1146                            User behavior analytics\n",
       "1147                                     Validation set\n",
       "1149                             Version space learning\n",
       "1339  File:Decision tree for IUPAC polymer nomenclat...\n",
       "1473                 Category:Artificial immune systems\n",
       "1556                         Category:Bayesian networks\n",
       "1557                          Category:Causal inference\n",
       "\n",
       "[1114 rows x 1 columns]"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Only the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_content70 = []\n",
    "\n",
    "def striphtml(data):\n",
    "    p = re.compile(r'<.*?>')\n",
    "    return p.sub('', data)\n",
    "\n",
    "for v in everything_pages:\n",
    "#def get_page_contents(page):\n",
    "    #for page in category_list:\n",
    "        query70 = 'http://en.wikipedia.org/w/api.php?action=query&prop=extracts&\\\n",
    "             rvprop=content&rvsection=0&format=json&pageids={}'.format(str(v))\n",
    "    \n",
    "        my_request70 = requests.get(query70).json()\n",
    "\n",
    "    \n",
    "        all_content70.append(striphtml(my_request70['query']['pages'][str(v)]['extract']).replace(\"'\",''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "every_text = pd.DataFrame(all_content70, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1114 entries, 0 to 1113\n",
      "Data columns (total 1 columns):\n",
      "text    1114 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 8.8+ KB\n"
     ]
    }
   ],
   "source": [
    "every_text.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "every_text.drop_duplicates(['text'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "every_text.reset_index(drop=True, inplace=True)\n",
    "only_titles.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "everything_puttogether = pd.concat([every_text, only_titles],axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "everything_puttogether.rename(columns={0:'text', 1 :'title'}, inplace=True)\n",
    "#everything_puttogether.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "everything_puttogether.drop(everything_puttogether.index[1110:], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()\n",
    "everything_puttogether['numerical_title'] = label.fit_transform(everything_puttogether['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(min_df = 1)\n",
    "machine_learning_matrix_count = count_vectorizer.fit_transform(everything_puttogether.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_learning_matrix_count.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "#everything_puttogether.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "machinelearning_matrix_df = pd.DataFrame(machine_learning_matrix_count.toarray(),\n",
    "                                       index=everything_puttogether.index,\n",
    "                                       columns=count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "#machinelearning_matrix_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df = 1)\n",
    "machine_learning_matrix_tfidf = tfidf_vectorizer.fit_transform(everything_puttogether.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1114x33438 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 365639 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_learning_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_matrix_tfidfdf = pd.DataFrame(machine_learning_matrix_tfidf.toarray(),\n",
    "                                       index=everything_puttogether.text,\n",
    "                                       columns=tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD and LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_svdmatrix = svd.fit_transform(machinelearning_matrix_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (5, 1114), indices imply (5, 1110)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   4295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4296\u001b[0;31m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4297\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, blocks, axes, do_integrity_check, fastpath)\u001b[0m\n\u001b[1;32m   2794\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2795\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_verify_integrity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3005\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmgr_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3006\u001b[0;31m                 \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3007\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtot_items\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   4279\u001b[0m     raise ValueError(\"Shape of passed values is {0}, indices imply {1}\".format(\n\u001b[0;32m-> 4280\u001b[0;31m         passed, implied))\n\u001b[0m\u001b[1;32m   4281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (5, 1114), indices imply (5, 1110)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-644-5a1ae4a4c22a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlsa_machincelearning_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmachine_learning_svdmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meverything_puttogether\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'component1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'component2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'component3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'component4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'component5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 mgr = self._init_ndarray(data, index, columns, dtype=dtype,\n\u001b[0;32m--> 306\u001b[0;31m                                          copy=copy)\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_ndarray\u001b[0;34m(self, values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   4301\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'values'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4302\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4303\u001b[0;31m         \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   4278\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4279\u001b[0m     raise ValueError(\"Shape of passed values is {0}, indices imply {1}\".format(\n\u001b[0;32m-> 4280\u001b[0;31m         passed, implied))\n\u001b[0m\u001b[1;32m   4281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (5, 1114), indices imply (5, 1110)"
     ]
    }
   ],
   "source": [
    "lsa_machincelearning_df = pd.DataFrame(machine_learning_svdmatrix,index=everything_puttogether.index, columns=['component1', 'component2', 'component3', 'component4', 'component5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_machincelearning_df['text'] = everything_puttogether.text\n",
    "lsa_machincelearning_df['title'] = everything_puttogether.title\n",
    "\n",
    "lsa_machincelearning_df.set_index('text', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lsa_machincelearning_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transpose and setting names to be aware of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.DataFrame(svd.components_, index=('component1','component2','component3','component4', 'component5'),\n",
    "                     columns=count_vectorizer.get_feature_names()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['abs 1' 'abs 2' 'abs 3' 'abs 4' 'abs 5'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-645-d1a9006595af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'abs 1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'abs 2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'abs 3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'abs 4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'abs 5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2159\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2161\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2162\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3622\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3623\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3624\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3625\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3626\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels ['abs 1' 'abs 2' 'abs 3' 'abs 4' 'abs 5'] not contained in axis"
     ]
    }
   ],
   "source": [
    "words.drop(['abs 1', 'abs 2', 'abs 3', 'abs 4', 'abs 5'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in range(0,5):\n",
    "words['abs_1'] = np.abs(words.component1)\n",
    "words['abs_2'] = np.abs(words.component2)\n",
    "words['abs_3'] = np.abs(words.component3)\n",
    "words['abs_4'] = np.abs(words.component4)\n",
    "words['abs_5'] = np.abs(words.component5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component1</th>\n",
       "      <th>component2</th>\n",
       "      <th>component3</th>\n",
       "      <th>component4</th>\n",
       "      <th>component5</th>\n",
       "      <th>abs_1</th>\n",
       "      <th>abs_2</th>\n",
       "      <th>abs_3</th>\n",
       "      <th>abs_4</th>\n",
       "      <th>abs_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.694945</td>\n",
       "      <td>0.122074</td>\n",
       "      <td>0.096686</td>\n",
       "      <td>-0.330776</td>\n",
       "      <td>-0.194853</td>\n",
       "      <td>0.694945</td>\n",
       "      <td>0.122074</td>\n",
       "      <td>0.096686</td>\n",
       "      <td>0.330776</td>\n",
       "      <td>0.194853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>0.386547</td>\n",
       "      <td>-0.182833</td>\n",
       "      <td>-0.045825</td>\n",
       "      <td>-0.011672</td>\n",
       "      <td>0.323981</td>\n",
       "      <td>0.386547</td>\n",
       "      <td>0.182833</td>\n",
       "      <td>0.045825</td>\n",
       "      <td>0.011672</td>\n",
       "      <td>0.323981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.250431</td>\n",
       "      <td>-0.322654</td>\n",
       "      <td>0.151737</td>\n",
       "      <td>0.566737</td>\n",
       "      <td>0.094705</td>\n",
       "      <td>0.250431</td>\n",
       "      <td>0.322654</td>\n",
       "      <td>0.151737</td>\n",
       "      <td>0.566737</td>\n",
       "      <td>0.094705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.233937</td>\n",
       "      <td>-0.142390</td>\n",
       "      <td>-0.026421</td>\n",
       "      <td>-0.048070</td>\n",
       "      <td>-0.122373</td>\n",
       "      <td>0.233937</td>\n",
       "      <td>0.142390</td>\n",
       "      <td>0.026421</td>\n",
       "      <td>0.048070</td>\n",
       "      <td>0.122373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.214957</td>\n",
       "      <td>-0.133432</td>\n",
       "      <td>-0.067340</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>0.097606</td>\n",
       "      <td>0.214957</td>\n",
       "      <td>0.133432</td>\n",
       "      <td>0.067340</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>0.097606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.206490</td>\n",
       "      <td>0.099251</td>\n",
       "      <td>-0.095501</td>\n",
       "      <td>-0.097733</td>\n",
       "      <td>0.016902</td>\n",
       "      <td>0.206490</td>\n",
       "      <td>0.099251</td>\n",
       "      <td>0.095501</td>\n",
       "      <td>0.097733</td>\n",
       "      <td>0.016902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displaystyle</th>\n",
       "      <td>0.169621</td>\n",
       "      <td>0.633975</td>\n",
       "      <td>-0.477357</td>\n",
       "      <td>0.411650</td>\n",
       "      <td>-0.029086</td>\n",
       "      <td>0.169621</td>\n",
       "      <td>0.633975</td>\n",
       "      <td>0.477357</td>\n",
       "      <td>0.411650</td>\n",
       "      <td>0.029086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.116146</td>\n",
       "      <td>-0.055551</td>\n",
       "      <td>-0.044512</td>\n",
       "      <td>0.073418</td>\n",
       "      <td>0.061043</td>\n",
       "      <td>0.116146</td>\n",
       "      <td>0.055551</td>\n",
       "      <td>0.044512</td>\n",
       "      <td>0.073418</td>\n",
       "      <td>0.061043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>0.101698</td>\n",
       "      <td>-0.018025</td>\n",
       "      <td>-0.027855</td>\n",
       "      <td>-0.050578</td>\n",
       "      <td>0.029234</td>\n",
       "      <td>0.101698</td>\n",
       "      <td>0.018025</td>\n",
       "      <td>0.027855</td>\n",
       "      <td>0.050578</td>\n",
       "      <td>0.029234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as</th>\n",
       "      <td>0.089681</td>\n",
       "      <td>-0.035556</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.015160</td>\n",
       "      <td>-0.004840</td>\n",
       "      <td>0.089681</td>\n",
       "      <td>0.035556</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>0.004840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be</th>\n",
       "      <td>0.083299</td>\n",
       "      <td>0.016882</td>\n",
       "      <td>-0.025042</td>\n",
       "      <td>-0.023934</td>\n",
       "      <td>0.027641</td>\n",
       "      <td>0.083299</td>\n",
       "      <td>0.016882</td>\n",
       "      <td>0.025042</td>\n",
       "      <td>0.023934</td>\n",
       "      <td>0.027641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>0.080992</td>\n",
       "      <td>-0.024231</td>\n",
       "      <td>0.017807</td>\n",
       "      <td>0.015621</td>\n",
       "      <td>0.004161</td>\n",
       "      <td>0.080992</td>\n",
       "      <td>0.024231</td>\n",
       "      <td>0.017807</td>\n",
       "      <td>0.015621</td>\n",
       "      <td>0.004161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>0.073428</td>\n",
       "      <td>-0.028080</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>-0.012085</td>\n",
       "      <td>-0.032380</td>\n",
       "      <td>0.073428</td>\n",
       "      <td>0.028080</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.012085</td>\n",
       "      <td>0.032380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with</th>\n",
       "      <td>0.069065</td>\n",
       "      <td>-0.024072</td>\n",
       "      <td>0.019063</td>\n",
       "      <td>0.005047</td>\n",
       "      <td>-0.002687</td>\n",
       "      <td>0.069065</td>\n",
       "      <td>0.024072</td>\n",
       "      <td>0.019063</td>\n",
       "      <td>0.005047</td>\n",
       "      <td>0.002687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>0.067036</td>\n",
       "      <td>-0.096053</td>\n",
       "      <td>0.010767</td>\n",
       "      <td>0.180524</td>\n",
       "      <td>0.005176</td>\n",
       "      <td>0.067036</td>\n",
       "      <td>0.096053</td>\n",
       "      <td>0.010767</td>\n",
       "      <td>0.180524</td>\n",
       "      <td>0.005176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mathbf</th>\n",
       "      <td>0.065828</td>\n",
       "      <td>0.438243</td>\n",
       "      <td>0.732976</td>\n",
       "      <td>0.127575</td>\n",
       "      <td>-0.043459</td>\n",
       "      <td>0.065828</td>\n",
       "      <td>0.438243</td>\n",
       "      <td>0.732976</td>\n",
       "      <td>0.127575</td>\n",
       "      <td>0.043459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>0.057337</td>\n",
       "      <td>0.015380</td>\n",
       "      <td>-0.008520</td>\n",
       "      <td>-0.043045</td>\n",
       "      <td>-0.017806</td>\n",
       "      <td>0.057337</td>\n",
       "      <td>0.015380</td>\n",
       "      <td>0.008520</td>\n",
       "      <td>0.043045</td>\n",
       "      <td>0.017806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>can</th>\n",
       "      <td>0.055264</td>\n",
       "      <td>-0.000712</td>\n",
       "      <td>-0.012747</td>\n",
       "      <td>0.037381</td>\n",
       "      <td>-0.049946</td>\n",
       "      <td>0.055264</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.012747</td>\n",
       "      <td>0.037381</td>\n",
       "      <td>0.049946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>an</th>\n",
       "      <td>0.051406</td>\n",
       "      <td>-0.030561</td>\n",
       "      <td>-0.008975</td>\n",
       "      <td>-0.006176</td>\n",
       "      <td>-0.017130</td>\n",
       "      <td>0.051406</td>\n",
       "      <td>0.030561</td>\n",
       "      <td>0.008975</td>\n",
       "      <td>0.006176</td>\n",
       "      <td>0.017130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>or</th>\n",
       "      <td>0.049150</td>\n",
       "      <td>-0.044380</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>-0.030603</td>\n",
       "      <td>-0.004755</td>\n",
       "      <td>0.049150</td>\n",
       "      <td>0.044380</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.030603</td>\n",
       "      <td>0.004755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              component1  component2  component3  component4  component5  \\\n",
       "the             0.694945    0.122074    0.096686   -0.330776   -0.194853   \n",
       "of              0.386547   -0.182833   -0.045825   -0.011672    0.323981   \n",
       "and             0.250431   -0.322654    0.151737    0.566737    0.094705   \n",
       "to              0.233937   -0.142390   -0.026421   -0.048070   -0.122373   \n",
       "in              0.214957   -0.133432   -0.067340    0.069073    0.097606   \n",
       "is              0.206490    0.099251   -0.095501   -0.097733    0.016902   \n",
       "displaystyle    0.169621    0.633975   -0.477357    0.411650   -0.029086   \n",
       "for             0.116146   -0.055551   -0.044512    0.073418    0.061043   \n",
       "that            0.101698   -0.018025   -0.027855   -0.050578    0.029234   \n",
       "as              0.089681   -0.035556   -0.000002   -0.015160   -0.004840   \n",
       "be              0.083299    0.016882   -0.025042   -0.023934    0.027641   \n",
       "are             0.080992   -0.024231    0.017807    0.015621    0.004161   \n",
       "by              0.073428   -0.028080    0.002243   -0.012085   -0.032380   \n",
       "with            0.069065   -0.024072    0.019063    0.005047   -0.002687   \n",
       "on              0.067036   -0.096053    0.010767    0.180524    0.005176   \n",
       "mathbf          0.065828    0.438243    0.732976    0.127575   -0.043459   \n",
       "this            0.057337    0.015380   -0.008520   -0.043045   -0.017806   \n",
       "can             0.055264   -0.000712   -0.012747    0.037381   -0.049946   \n",
       "an              0.051406   -0.030561   -0.008975   -0.006176   -0.017130   \n",
       "or              0.049150   -0.044380    0.001392   -0.030603   -0.004755   \n",
       "\n",
       "                 abs_1     abs_2     abs_3     abs_4     abs_5  \n",
       "the           0.694945  0.122074  0.096686  0.330776  0.194853  \n",
       "of            0.386547  0.182833  0.045825  0.011672  0.323981  \n",
       "and           0.250431  0.322654  0.151737  0.566737  0.094705  \n",
       "to            0.233937  0.142390  0.026421  0.048070  0.122373  \n",
       "in            0.214957  0.133432  0.067340  0.069073  0.097606  \n",
       "is            0.206490  0.099251  0.095501  0.097733  0.016902  \n",
       "displaystyle  0.169621  0.633975  0.477357  0.411650  0.029086  \n",
       "for           0.116146  0.055551  0.044512  0.073418  0.061043  \n",
       "that          0.101698  0.018025  0.027855  0.050578  0.029234  \n",
       "as            0.089681  0.035556  0.000002  0.015160  0.004840  \n",
       "be            0.083299  0.016882  0.025042  0.023934  0.027641  \n",
       "are           0.080992  0.024231  0.017807  0.015621  0.004161  \n",
       "by            0.073428  0.028080  0.002243  0.012085  0.032380  \n",
       "with          0.069065  0.024072  0.019063  0.005047  0.002687  \n",
       "on            0.067036  0.096053  0.010767  0.180524  0.005176  \n",
       "mathbf        0.065828  0.438243  0.732976  0.127575  0.043459  \n",
       "this          0.057337  0.015380  0.008520  0.043045  0.017806  \n",
       "can           0.055264  0.000712  0.012747  0.037381  0.049946  \n",
       "an            0.051406  0.030561  0.008975  0.006176  0.017130  \n",
       "or            0.049150  0.044380  0.001392  0.030603  0.004755  "
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.sort_values('abs_1',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df = 1)\n",
    "machine_learning_matrix_tfidf = tfidf_vectorizer.fit_transform(everything_puttogether.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1114x33438 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 365639 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_learning_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "machine_learning_matrix_tfidfdf = pd.DataFrame(machine_learning_matrix_tfidf.toarray(),\n",
    "                                       index=everything_puttogether.text,\n",
    "                                       columns=tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer2 = TfidfVectorizer(min_df = 1)\n",
    "machine_learning_title = tfidf_vectorizer2.fit_transform(everything_puttogether.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_matrix_textdf = pd.DataFrame(machine_learning_title.toarray(),\n",
    "                                       index=everything_puttogether.text,\n",
    "                                       columns=tfidf_vectorizer2.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_sample = machine_learning_matrix_textdf.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000006</th>\n",
       "      <th>00001</th>\n",
       "      <th>00008</th>\n",
       "      <th>00024</th>\n",
       "      <th>00031305</th>\n",
       "      <th>0003268</th>\n",
       "      <th>00034</th>\n",
       "      <th>...</th>\n",
       "      <th>吳恩達</th>\n",
       "      <th>在雲端運算環境使用r和mpi</th>\n",
       "      <th>快速在aws建立r和pbdmpi的使用環境</th>\n",
       "      <th>李飛飛</th>\n",
       "      <th>李飞飞</th>\n",
       "      <th>松山研究室について</th>\n",
       "      <th>林智仁</th>\n",
       "      <th>ﬂexibility</th>\n",
       "      <th>ﬂock</th>\n",
       "      <th>ﬂocking</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Transfer learning or inductive transfer is a research problem in machine learning that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem. For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks. This area of research bears some relation to the long history of psychological literature on transfer of learning, although formal ties between the two fields are limited.\\n\\n\\n\\nHistory\\nThe earliest cited work on transfer in machine learning is attributed to Lorien Pratt, who formulated the discriminability-based transfer (DBT) algorithm in 1993.\\nIn 1997, the journal Machine Learning published a special issue devoted to transfer learning, and by 1998, the field had advanced to include multi-task learning, along with a more formal analysis of its theoretical foundations. Learning to Learn, edited by Pratt and Sebastian Thrun, is a 2012 review of the subject.\\nTransfer learning has also been applied in cognitive science, with the journal Connection Science publishing a special issue on reuse of neural networks through transfer in 1996.\\nNotably, scientists have developed algorithms for transfer learning in Markov logic networks and Bayesian networks. Researchers have also applied techniques for transfer to problems in text classification, and spam filtering.\\nSee also\\nMulti-task learning\\nDomain Adaptation\\nSources\\nThrun, Sebastian; Pratt, Lorien (6 December 2012). Learning to Learn. Springer Science &amp;amp; Business Media. ISBN 978-1-4615-5529-2. \\nReferences</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 33438 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     00  000  0000  00000006  \\\n",
       "text                                                                           \n",
       "Transfer learning or inductive transfer is a re...  0.0  0.0   0.0       0.0   \n",
       "\n",
       "                                                    00001  00008  00024  \\\n",
       "text                                                                      \n",
       "Transfer learning or inductive transfer is a re...    0.0    0.0    0.0   \n",
       "\n",
       "                                                    00031305  0003268  00034  \\\n",
       "text                                                                           \n",
       "Transfer learning or inductive transfer is a re...       0.0      0.0    0.0   \n",
       "\n",
       "                                                     ...     吳恩達  \\\n",
       "text                                                 ...           \n",
       "Transfer learning or inductive transfer is a re...   ...     0.0   \n",
       "\n",
       "                                                    在雲端運算環境使用r和mpi  \\\n",
       "text                                                                 \n",
       "Transfer learning or inductive transfer is a re...             0.0   \n",
       "\n",
       "                                                    快速在aws建立r和pbdmpi的使用環境  \\\n",
       "text                                                                        \n",
       "Transfer learning or inductive transfer is a re...                    0.0   \n",
       "\n",
       "                                                    李飛飛  李飞飞  松山研究室について  林智仁  \\\n",
       "text                                                                           \n",
       "Transfer learning or inductive transfer is a re...  0.0  0.0        0.0  0.0   \n",
       "\n",
       "                                                    ﬂexibility  ﬂock  ﬂocking  \n",
       "text                                                                           \n",
       "Transfer learning or inductive transfer is a re...         0.0   0.0      0.0  \n",
       "\n",
       "[1 rows x 33438 columns]"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_df = machine_learning_matrix_tfidfdf.append(search_sample)\n",
    "#search_df.dropna(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd_truncated = TruncatedSVD(n_components=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "svdtrun_matrix2 = svd_truncated.fit_transform(search_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_truncateddf = pd.DataFrame(svdtrun_matrix2, index=search_df.index, columns= (range(0,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#need to use loc because I made the index the text\n",
    "#numbers to text will not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_vector = svd_truncateddf.loc[search_sample.index]\n",
    "#search_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels [1] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-723-3c3f2a0e611a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcos_simdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2159\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2161\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2162\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3622\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3623\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3624\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3625\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3626\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels [1] not contained in axis"
     ]
    }
   ],
   "source": [
    "cos_simdf.drop(1, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_simdf.rename(columns={0:'cos_similarity'}, inplace=True)\n",
    "cos_simdf.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svd_truncateddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_truncateddf['cosine_similarity'] = cos_simdf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>In computer science, genetic memory refers to an artificial neural network combination of genetic algorithm and the mathematical model of sparse distributed memory. It can be used to predict weather patterns. Genetic memory and genetic algorithms have also gained an interest in the creation of artificial life.\\nReferences\\n\\n</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transfer learning or inductive transfer is a research problem in machine learning that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem. For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks. This area of research bears some relation to the long history of psychological literature on transfer of learning, although formal ties between the two fields are limited.\\n\\n\\n\\nHistory\\nThe earliest cited work on transfer in machine learning is attributed to Lorien Pratt, who formulated the discriminability-based transfer (DBT) algorithm in 1993.\\nIn 1997, the journal Machine Learning published a special issue devoted to transfer learning, and by 1998, the field had advanced to include multi-task learning, along with a more formal analysis of its theoretical foundations. Learning to Learn, edited by Pratt and Sebastian Thrun, is a 2012 review of the subject.\\nTransfer learning has also been applied in cognitive science, with the journal Connection Science publishing a special issue on reuse of neural networks through transfer in 1996.\\nNotably, scientists have developed algorithms for transfer learning in Markov logic networks and Bayesian networks. Researchers have also applied techniques for transfer to problems in text classification, and spam filtering.\\nSee also\\nMulti-task learning\\nDomain Adaptation\\nSources\\nThrun, Sebastian; Pratt, Lorien (6 December 2012). Learning to Learn. Springer Science &amp;amp; Business Media. ISBN 978-1-4615-5529-2. \\nReferences</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A genetic algorithm (GA) is an algorithm used to find approximate solutions to difficult-to-solve problems through application of the principles of evolutionary biology to computer science. Genetic algorithms use biologically-derived techniques such as inheritance, mutation, natural selection, and recombination. Genetic algorithms are a particular class of evolutionary algorithms.</th>\n",
       "      <td>0.641187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In computer programming, genetic representation is a way of representing solutions/individuals in evolutionary computation methods. Genetic representation can encode appearance, behavior, physical qualities of individuals. Designing a good genetic representation that is expressive and evolvable is a hard problem in evolutionary computation. Difference in genetic representations is one of the major criteria drawing a line between known classes of evolutionary computation.\\nTerminology often comes by analogy with natural genetics. The block of computer memory that represents one candidate solution is called an individual. The data in that block is called a chromosome. Each chromosome consists of genes. The possible values of a particular gene are called alleles. A programmer may represent all the individuals of a population using binary encoding, permutational encoding, encoding by tree, or any one of several other representations.\\nGenetic algorithms use linear binary representations. The most standard one is an array of bits. Arrays of other types and structures can be used in essentially the same way. The main property that makes these genetic representations convenient is that their parts are easily aligned due to their fixed size. This facilitates simple crossover operation. Variable length representations were also explored in Genetic algorithms, but crossover implementation is more complex in this case.\\nEvolution strategy uses linear real-valued representations, e.g. an array of real values. It uses mostly gaussian mutation and blending/averaging crossover.\\nGenetic programming (GP) pioneered tree-like representations and developed genetic operators suitable for such representations. Tree-like representations are used in GP to represent and evolve functional programs with desired properties.\\nHuman-based genetic algorithm (HBGA) offers a way to avoid solving hard representation problems by outsourcing all genetic operators to outside agents, in this case, humans. The algorithm has no need for knowledge of a particular fixed genetic representation as long as there are enough external agents capable of handling those representations, allowing for free-form and evolving genetic representations.\\nCommon genetic representations\\nbinary array\\nbinary tree\\nnatural language\\nparse tree\\ndirected graph\\nReferences and notes</th>\n",
       "      <td>0.629881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parity problems are widely used as benchmark problems in genetic programming but inherited from the artificial neural network community. Parity is calculated by summing all the binary inputs and reporting if the sum is odd or even. This is considered difficult because:\\na very simple artificial neural network cannot solve it, and\\nall inputs need to be considered and a change to any one of them changes the answer.\\nReferences\\nFoundations of Genetic Programming\\n</th>\n",
       "      <td>0.618790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    cosine_similarity\n",
       "text                                                                 \n",
       "In computer science, genetic memory refers to a...           1.000000\n",
       "Transfer learning or inductive transfer is a re...           1.000000\n",
       "A genetic algorithm (GA) is an algorithm used t...           0.641187\n",
       "In computer programming, genetic representation...           0.629881\n",
       "Parity problems are widely used as benchmark pr...           0.618790"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_truncateddf[['cosine_similarity']].sort_values('cosine_similarity', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "#everything_puttogether[everything_puttogether['text'].str.contains('genetic memory')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5 related articles are: \n",
    "* Parity Learning\n",
    "* Genetic representation\n",
    "* Genetic algorithms\n",
    "* Transfer Learning\n",
    "* Gentetic memory(computer science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
